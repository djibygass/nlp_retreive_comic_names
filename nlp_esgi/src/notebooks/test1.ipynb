{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T09:02:47.470592Z",
     "start_time": "2023-10-12T09:02:46.444770Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T09:04:01.230571Z",
     "start_time": "2023-10-12T09:04:01.210191Z"
    }
   },
   "id": "d6ccf60ec4b1d1f3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            video_name  \\\n0    Le Barbecue Disney - La chanson de Frédéric Fr...   \n1    Le Roi et l'Oiseau - La Chronique de Christine...   \n2    L'amour du lac - La chronique d'Hippolyte Gira...   \n3    La fille de la piscine de Léa Tourret - La chr...   \n4    \"Le soleil va moins faire son malin quand Jean...   \n..                                                 ...   \n994  Au Ces de Las Vegas des innovations à gogo et ...   \n995  Le questionnaire Jupiproust de Frédérique Matonti   \n996          Raphael - La Nuit N'en Finit Plus (cover)   \n997  Des sachets de drogue estampillés Haribeu sais...   \n998  \"1984\" par Xavier Coste : Prix Bd Fnac France ...   \n\n                                               is_name  is_comic  \\\n0                          [0, 0, 0, 0, 0, 0, 0, 1, 1]         1   \n1                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]         1   \n2                       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]         1   \n3           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]         0   \n4    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...         0   \n..                                                 ...       ...   \n994   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]         0   \n995                                 [0, 0, 0, 0, 0, 0]         1   \n996                        [0, 0, 0, 0, 0, 0, 0, 0, 0]         0   \n997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1   \n998                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]         0   \n\n                 comic_name  \n0       [\"Frédéric Fromet\"]  \n1    [\"Christine Gonzalez\"]  \n2    [\"Hippolyte Girardot\"]  \n3                        []  \n4                        []  \n..                      ...  \n994                      []  \n995                      []  \n996                      []  \n997                      []  \n998                      []  \n\n[999 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n      <th>is_name</th>\n      <th>is_comic</th>\n      <th>comic_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Le Barbecue Disney - La chanson de Frédéric Fr...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n      <td>1</td>\n      <td>[\"Frédéric Fromet\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Le Roi et l'Oiseau - La Chronique de Christine...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n      <td>1</td>\n      <td>[\"Christine Gonzalez\"]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L'amour du lac - La chronique d'Hippolyte Gira...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n      <td>1</td>\n      <td>[\"Hippolyte Girardot\"]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>La fille de la piscine de Léa Tourret - La chr...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"Le soleil va moins faire son malin quand Jean...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <td>Au Ces de Las Vegas des innovations à gogo et ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Le questionnaire Jupiproust de Frédérique Matonti</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n      <td>1</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>Raphael - La Nuit N'en Finit Plus (cover)</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Des sachets de drogue estampillés Haribeu sais...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>\"1984\" par Xavier Coste : Prix Bd Fnac France ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>999 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T09:04:04.422348Z",
     "start_time": "2023-10-12T09:04:04.387209Z"
    }
   },
   "id": "7c49bd002142b713"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "52b16a6e6d7ed61c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m token[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39misupper() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(token) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Load your dataset\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/train.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Create a new DataFrame to hold the tokenized data\u001B[39;00m\n\u001B[1;32m     31\u001B[0m tokenized_data \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvideo_name\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_name\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;66;03m# ... other columns as needed\u001B[39;00m\n\u001B[1;32m     36\u001B[0m }\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/nlp_retreive_comic_names/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/nlp_retreive_comic_names/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/nlp_retreive_comic_names/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/nlp_retreive_comic_names/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/nlp_retreive_comic_names/lib/python3.11/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/train.csv'"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize_and_label(video_name):\n",
    "    # Tokenize the video name. This could be a simple split on whitespace,\n",
    "    # or something more sophisticated depending on your needs.\n",
    "    tokens = word_tokenize(video_name)\n",
    "\n",
    "    # Generate labels for each token. You'll need to implement the logic\n",
    "    # to determine whether each token is a name.\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        if is_name(token):  # You'll need to define the is_name logic.\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    return tokens, labels\n",
    "  # This is a function you would need to create\n",
    "\n",
    "def is_name(token):\n",
    "    # Naive check for a name. A real check might look the token up in a list\n",
    "    # of known names, use a machine learning model, etc.\n",
    "    return token[0].isupper() and len(token) > 1\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/train.csv')\n",
    "\n",
    "# Create a new DataFrame to hold the tokenized data\n",
    "tokenized_data = {\n",
    "    'video_name': [],\n",
    "    'tokens': [],\n",
    "    'is_name': [],\n",
    "    # ... other columns as needed\n",
    "}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    video_name = row['video_name']\n",
    "    tokens, labels = tokenize_and_label(video_name)  # Your function to tokenize and create labels\n",
    "\n",
    "    tokenized_data['video_name'].append(video_name)\n",
    "    tokenized_data['tokens'].append(tokens)\n",
    "    tokenized_data['is_name'].append(labels)\n",
    "    # ... handle other columns as needed\n",
    "\n",
    "# Convert the tokenized data into a DataFrame\n",
    "tokenized_df = pd.DataFrame(tokenized_data)\n",
    "\n",
    "# Save the new DataFrame to a new CSV file\n",
    "tokenized_df.to_csv('/Users/Gassama/5IABD/NLP/projets/TD1/nlp_esgi/src/data/raw/corrected_train.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:12:30.683456Z",
     "start_time": "2023-11-07T23:12:21.524724Z"
    }
   },
   "id": "3ed2504f21fe9b9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62203d925c2f1b06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
